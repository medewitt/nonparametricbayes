# This work is copyright 2021 by BayesCamp Ltd
# (registered in England and Wales, company
# number 10666858) and licensed under a
# Creative Commons Attribution 4.0 International
# License.
#
# You are free to:
# Share - copy and redistribute the material in
#         any medium or format.
# Adapt - remix, transform, and build upon the material
#         for any purpose, even commercially.
# The licensor (BayesCamp Ltd) cannot revoke these
# freedoms as long as you follow the license terms.
#
#
# In using this work, you are subject to the following terms:
# Attribution - You must give appropriate credit,
#               provide a link to the license
#               (https://creativecommons.org/licenses/by/4.0/legalcode),
#               and indicate if changes were made. You may
#               do so in any reasonable manner, but not in
#               any way that suggests the licensor endorses
#               you or your use.
# No additional restrictions - You may not apply legal terms
#                              or technological measures that
#                              legally restrict others from
#                              doing anything the license permits.
# Notices - You do not have to comply with the license for elements
#           of the material in the public domain or where your use
#           is permitted by an applicable exception or limitation.
#         - No warranties are given. The license may not give
#           you all of the permissions necessary for your
#           intended use. For example, other rights such as
#           publicity, privacy, or moral rights may limit
#           how you use the material.



# non-parametric Bayesian updating by kernel densities
# this script will run four chains on four cores
#


setwd('~/instance1')

library(dplyr)
library(diptest)
library(rstan)
rstan_options(auto_write = TRUE)
extract<-rstan::extract # avoid ambiguity
options(mc.cores = 4)


# change these for parallel instances of R
r_overall_seed<-   700000
stan_overall_seed<-900000


###########################################################
# Section 1                                               #
# Define all Stan models and compile them                 #
###########################################################


stan_all_code <- '
data {
int n;
real x1[n];
real x2[n];
int y[n];
}
parameters {
real beta0;
real beta1;
real beta2;
}
model {
real mu[n];
real prob[n];
beta0 ~ normal(0,4);
beta1 ~ normal(0,4);
beta2 ~ normal(0,4);
for(i in 1:n) {
mu[i] = beta0 + beta1*x1[i] + beta2*x2[i];
prob[i] = exp(mu[i])/(1+exp(mu[i]));
target += bernoulli_lpmf(y[i] | prob[i]);
}
}
'
stan_all_fit_model <- stan_model(model_code=stan_all_code)

stan_next_code <- '
data {
int n;
real x1[n];
real x2[n];
int y[n];
vector[3] priormean;
matrix[3,3] priorcovar;
}
parameters {
vector[3] beta;
}
model {
real mu[n];
real prob[n];
beta ~ multi_normal(priormean,priorcovar);
for(i in 1:n) {
mu[i] = beta[1] + beta[2]*x1[i] + beta[3]*x2[i];
prob[i] = exp(mu[i])/(1+exp(mu[i]));
target += bernoulli_lpmf(y[i] | prob[i]);
}
}
'
stan_next_fit_model <- stan_model(model_code=stan_next_code)

stan_kernel_code <- '
data {
int n;
int k; // draws in the prior
int p; // columns in the prior; this should NOT include __lp, for example, which we will ignore
real x1[n];
real x2[n];
int y[n];
matrix[k,p] prior;
real bandwidth[p];
}
parameters {
real beta[p]; // this is simpler as a vector
}
model {
real mu[n];
real prob[n];
real logpriorprob;
real priorprob;
// no prior specified here, so they are uniform
for(i in 1:n) {
mu[i] = beta[1] + beta[2]*x1[i] + beta[3]*x2[i];
prob[i] = exp(mu[i])/(1+exp(mu[i]));
// increment log-posterior by log-likelihood
target += bernoulli_lpmf(y[i] | prob[i]);
}
// increment log-posterior by log-prior
priorprob = 0.0;
for(i in 1:k) {
logpriorprob = 0.0;
for(j in 1:p) {
logpriorprob += normal_lpdf(beta[j] | prior[i,j], bandwidth[j]);
}
priorprob += exp(logpriorprob); // add all kernels together
}
priorprob = priorprob / (k+0.0); // average over k draws in the prior
target += log(priorprob); // add to log-likelihood!
}
'
stan_kernel_fit_model <- stan_model(model_code=stan_kernel_code)

stan_kernel_cube_code <- '
data {
int n;
int k; // number of non-zero-count hypercubes (bins) in the prior
int k_draws; // draws in the prior
int p; // columns in the prior; this should NOT include the count per hypercube
int<lower=1> count[k]; // number of draws in each hypercube
real x1[n];
real x2[n];
int y[n];
matrix[k,p] prior;
real bandwidth[p];
}
transformed data {
int<lower=1> sum_count;
sum_count = sum(count);
}
parameters {
real beta[3]; // this is simpler as a vector
}
model {
real mu[n];
real prob[n];
real logcubeprob;
real priorprob;
// no prior specified here, so they are uniform
for(i in 1:n) {
mu[i] = beta[1] + beta[2]*x1[i] + beta[3]*x2[i];
prob[i] = exp(mu[i])/(1+exp(mu[i]));
// increment log-posterior by log-likelihood
target += bernoulli_lpmf(y[i] | prob[i]);
}
// increment log-posterior by log-prior
priorprob = 0.0;
for(i in 1:k) {
logcubeprob = 0.0;
for(j in 1:p) {
logcubeprob += normal_lpdf(beta[j] | prior[i,j], bandwidth[j]); // multivariate distribution in parameter space
}
priorprob += count[i]*exp(logcubeprob); // add all kernels together, weighted by count
}
priorprob = priorprob / (sum_count+0.0); // weighted average over all draws in the prior
target += log(priorprob); // add to log-likelihood!
}
'
stan_kernel_cube_fit_model <- stan_model(model_code=stan_kernel_cube_code)



stan_beta_code <- '
functions{
int count_neighbours(int k, int p, real[] proposal, matrix prior, real[] beta_widths) {
  // identify neighbour prior draws
  int n_neighbours=0;
  int neighbour_p=0;
  for(i in 1:k) {
    neighbour_p=0;
    for(j in 1:p) {
      if(fabs(prior[i,j]-proposal[j])<(0.99*beta_widths[j])) neighbour_p+=1;
      // 0.99 because we dont want rounding error to nudge a prior draw out of the domain of beta_ldpf()
    }
    if(neighbour_p==p) {
      n_neighbours+=1;
    }
  }
return(n_neighbours);
}

int[] find_neighbours(int k, int p, real[] proposal, matrix prior, real[] beta_widths, int n_neighbours) {
  // identify neighbour prior draws
  int loopcount=0;
  int neighbour_prior[n_neighbours];
  for(i in 1:k) {
    int neighbour_p=0;
    for(j in 1:p) {
      if(fabs(prior[i,j]-proposal[j])<(0.99*beta_widths[j])) neighbour_p+=1;
      // 0.99 because we dont want rounding error to nudge a prior draw out of the domain of beta_ldpf()
    }
    if(neighbour_p==p) {
      loopcount+=1;
      neighbour_prior[loopcount]=i;
    }
  }
  return(neighbour_prior);
}
}

data {
  int n;
  int k; // draws in the prior (in the hypercuboid version, including the phony one)
  int p; // columns in the prior; this should NOT include __lp
  real<lower=0> betapars; // shared alpha and beta parameters for the beta distribution
  real<lower=0> beta_widths[p];
  matrix[k,p] prior;
  real x1[n];
  real x2[n];
  int y[n];
}

parameters {
  real beta[3]; // this is simpler as a vector
}

model {
  real mu[n];
  real prob[n];
  real logpriorprob;
  real priorprob;
  int n_neighbours = count_neighbours(k, p, beta, prior, beta_widths);
  int neighbour_prior[n_neighbours] = find_neighbours(k, p, beta, prior, beta_widths, n_neighbours);

  for(i in 1:n) {
    mu[i] = beta[1] + beta[2]*x1[i] + beta[3]*x2[i];
    prob[i] = exp(mu[i])/(1+exp(mu[i]));
    // increment log-posterior by log-likelihood
    target += bernoulli_lpmf(y[i] | prob[i]);
  }
  // increment log-posterior by log-prior
  priorprob = 0.0;
  for(i in 1:n_neighbours) {
    logpriorprob = 0.0;
    for(j in 1:p) {
      logpriorprob += beta_lpdf(0.5+(beta[j]-prior[neighbour_prior[i],j])/(2*beta_widths[j]) | betapars, betapars);
    }
    priorprob += exp(logpriorprob); // add all kernels densities (not log-densities) together
  }
  priorprob = priorprob / (k+0.0); // average over k draws in the prior
  target += log(priorprob); // add log-prior to log-likelihood!
}
'
stan_beta_fit_model <- stan_model(model_code=stan_beta_code)







###########################################################
# Section 2                                               #
# Define function                                         #
###########################################################

# define all arguments here:
n<-2000 # n of data observations
batches<-10 # batches of data
n_of_chains<-4
true_beta0<-2
true_beta1<-0.5
true_beta2<-(-1.5)
r_seed<-r_overall_seed+10000
stan_first_fit_seed<-stan_overall_seed+10000
stan_next_fit_seed<-stan_overall_seed+20000
stan_kernel_fit_seed<-stan_overall_seed+30000
stan_kernel_cube_fit_seed<-stan_overall_seed+40000
stan_beta_fit_seed<-stan_overall_seed+50000
n_of_draws_per_chain<-1000 # sample this many for kernel method
n_of_draws_per_chain_beta<-1000 # sample for beta kernel method
bandwidth<-0.08 # kernel Gaussian bandwidth for hypercube centroids
parameter_bins<-10 # number of hypercubes across each dimension in parameter space
bw_scaling<-1 # controls hypercube kernel size relative to posterior
expit<-function(x) { exp(x)/(1+exp(x)) } # inverse logistic function
betapars<-8 # shared alpha and beta parameters for the beta distribution
currentiter<-1 # this is just used for live progress display

# # overwrite with seeds for a dodgy simulation
# badoldsim<-readRDS('bad_sim_results_3.rds')
# r_seed<-badoldsim$r_seed
# stan_all_fit_seed<-badoldsim$stan_all_fit_seed
# stan_first_fit_seed<-badoldsim$stan_first_fit_seed
# stan_next_fit_seed<-badoldsim$stan_next_fit_seed
# stan_kernel_fit_seed<-badoldsim$stan_kernel_fit_seed
# stan_kernel_cube_fit_seed<-badoldsim$stan_kernel_cube_fit_seed


# initial draw picking function
init_draw<-function(n_chains,prior_draws) {
  init<-list(list(beta=as.numeric(prior_draws[sample(1:NROW(prior_draws),1),])))
  if(n_chains>1) {
    for(i in 2:n_chains) {
      init[[i]]<-list(beta=as.numeric(prior_draws[sample(1:NROW(prior_draws),1),]))
    }
  }
  return(init)
}


kernelsim<-function(n,
                    batches,
                    n_of_chains,
                    true_beta0,
                    true_beta1,
                    true_beta2,
                    r_seed,
                    stan_all_fit_seed,
                    stan_first_fit_seed,
                    stan_next_fit_seed,
                    stan_kernel_fit_seed,
                    stan_kernel_cube_fit_seed,
                    stan_beta_fit_seed,
                    n_of_draws_per_chain,
                    n_of_draws_per_chain_beta,
                    parameter_bins,
                    bw_scaling,
                    stan_all_fit_model,
                    stan_next_fit_model,
                    stan_kernel_fit_model,
                    stan_kernel_cube_fit_model,
                    stan_beta_fit_model,
                    betapars,
                    currentiter) {

  set.seed(r_seed)
  # checks
  if(n%%batches!=0) stop("n is not divisible by batches")

  # generate batches of data
  x1<-rnorm(n,0,1)
  x2<-(x1/1.8)+rnorm(n,0,0.8)
  y<-rbinom(n,size=1,prob=expit(true_beta0+(true_beta1*x1)+(true_beta2*x2)))
  # the MLEs by iterative reweighted least squares:
  mles<-summary(glm(y~x1+x2,family=binomial))$coefficients

  # split the data into batches
  data_batch<-NULL
  for(i in 1:batches) {
    batch_start<-(i-1)*(n/batches)+1
    batch_end<-i*(n/batches)
    data_batch[[i]] <- list(x1=x1[batch_start:batch_end],
                            x2=x2[batch_start:batch_end],
                            y=y[batch_start:batch_end])
  }


  ######################################################
  # what if we analysed all together (the "right" answer)?
  stan_all_time<-list(Sys.time())
  # note that this counts all data, the others all but the first batch
  cat(paste("now running simulation number",currentiter,"-- all data model\n"))
  stan_all_fit <- sampling(stan_all_fit_model,
                           data=list(n=n,
                                     y=y,
                                     x1=x1,
                                     x2=x2),
                           chains=n_of_chains,
                           cores=4,
                           iter=2500+n_of_draws_per_chain,
                           warmup=2500,
                           seed=stan_all_fit_seed)
  print(stan_all_fit)
  stan_summary_all<-list(summary=summary(stan_all_fit)$summary,
                         posterior=extract(stan_all_fit))
  stan_all_time[[2]]<-Sys.time()

  # we monitor these lists:
  log_normal<-log_kernel<-log_hypercube<-log_beta<-NULL




  ######################################################
  # normal stats updating
  stan_first_fit <- sampling(stan_all_fit_model,
                             data=list(n=n/batches,
                                       y=data_batch[[1]]$y,
                                       x1=data_batch[[1]]$x1,
                                       x2=data_batch[[1]]$x2),
                             chains=n_of_chains,
                             cores=4,
                             iter=2500+n_of_draws_per_chain,
                             warmup=2500,
                             seed=stan_first_fit_seed)
  print(stan_first_fit)
  stan_summary_stats<-array(NA,dim=c(3,2,batches))
  stan_summary_stats[,,1]<-summary(stan_first_fit)$summary[1:3,c(1,3)]
  next_prior_means<-stan_summary_stats[,1,1]
  # this is used as the starting sample for kernel, hypercube and wavelet:
  first_samples<-samples<-extract(stan_first_fit)
  next_prior_covar<-cov(cbind(samples$beta0,samples$beta1,samples$beta2))

  # log for debug:
  log_normal[[1]]<-list(next_prior_means=next_prior_means,
                        next_prior_covar=next_prior_covar,
                        posterior=samples)

  stan_normal_stats_time<-list(Sys.time())
  for(j in 2:batches) {
    cat(paste("now running simulation number",currentiter,
              "-- normal stats model -- batch",j,"of",batches,"\n"))
    stan_next_fit <- sampling(stan_next_fit_model,
                              data=list(n=n/batches,
                                        y=data_batch[[j]]$y,
                                        x1=data_batch[[j]]$x1,
                                        x2=data_batch[[j]]$x2,
                                        priormean=next_prior_means,
                                        priorcovar=next_prior_covar),
                              chains=n_of_chains,
                              cores=4,
                              iter=2500+n_of_draws_per_chain,
                              warmup=2500,
                              seed=stan_next_fit_seed+29*j)
    print(stan_next_fit)
    stan_summary_stats[,,j]<-summary(stan_next_fit)$summary[1:3,c(1,3)]
    next_prior_means<-stan_summary_stats[,1,j]
    samples<-extract(stan_next_fit)
    next_prior_covar<-cov(samples$beta)
    # log for debug:
    log_normal[[j]]<-list(next_prior_means=next_prior_means,
                          next_prior_covar=next_prior_covar,
                          posterior=samples)

  }
  stan_normal_stats_time[[2]]<-Sys.time()




  ######################################################
  # kernel densities for priors
  next_prior_draws<-cbind(first_samples$beta0,
                          first_samples$beta1,
                          first_samples$beta2)
  next_prior_draws<-next_prior_draws[sample.int(n=NROW(next_prior_draws),
                                                size=n_of_chains*n_of_draws_per_chain),]

  kernel_setup<-function(n_of_chains,
                         next_prior_draws,
                         hartigan_p_threshold=0.05,
                         multimodal_boost=1.5) {
    p<-ncol(next_prior_draws)
    # get Sheather-Jones bandwidth
    bandwidth<-apply(next_prior_draws,2,bw.SJ)
    #bandwidth<-median(parameter_bandwidth)
    # check for multimodality
    # loop over the parameters
    dipstats<-rep(NA,3)
    loopcount<-1
    dip_p<-rep(0.01,3)
    while(loopcount<100 & min(dip_p)<hartigan_p_threshold) {
      # get maximum Hartigans' dip statistic and increase bandwidth until non-sig
      for(i in 1:3) {
        tempdens<-density(next_prior_draws[,i],bw=bandwidth[i])
        tempscale<-n_of_chains*n_of_draws_per_chain/round(sum(tempdens$y))
        dip_p[i]<-unlist(diptest::dip.test(rep(tempdens$x,round(tempscale*tempdens$y)))$p.value)
        if(loopcount>1 & dip_p[i]<hartigan_p_threshold) { bandwidth[i]<-bandwidth[i]*multimodal_boost }
      }
      loopcount<-loopcount+1
    }
    if(loopcount>99) { stop("Unable to find unimodal univariate kernel bandwidth after 100 expansions") }

    # get initial values
    inits<-init_draw(n_of_chains,next_prior_draws)

    return(list(bandwidth=bandwidth,
                loopcount=loopcount,
                inits=inits))
  }

  # setup after first batch of data
  kernel_vars<-kernel_setup(n_of_chains,next_prior_draws)

  # log for debug:
  log_kernel[[1]]<-list(next_prior_draws=next_prior_draws,
                        bandwidth=kernel_vars$bandwidth,
                        loopcount=kernel_vars$loopcount,
                        inits=kernel_vars$inits)

  stan_summary_kernel<-array(NA,dim=c(3,2,batches))
  stan_summary_kernel[,,1]<-summary(stan_first_fit)$summary[1:3,c(1,3)]
  stan_kernel_time<-list(Sys.time())
  for(j in 2:batches) {
    cat(paste("now running simulation number",currentiter,
              "-- kernel model -- batch",j,"of",batches,"\n"))

    stan_kernel_fit<-stan(model_code=stan_kernel_code,
                          data=list(n=n/batches,
                                    y=data_batch[[j]]$y,
                                    x1=data_batch[[j]]$x1,
                                    x2=data_batch[[j]]$x2,
                                    k=NROW(next_prior_draws),
                                    p=NCOL(next_prior_draws),
                                    prior=next_prior_draws,
                                    bandwidth=kernel_vars$bandwidth),
                          chains=n_of_chains,
                          cores=4,
                          iter=2500+n_of_draws_per_chain,
                          warmup=2500,
                          seed=stan_kernel_fit_seed+991*j,
                          init=kernel_vars$inits)
    print(stan_kernel_fit)
    stan_summary_kernel[,,j]<-summary(stan_kernel_fit)$summary[1:3,c(1,3)]
    next_prior_draws<-extract(stan_kernel_fit)$beta
    kernel_vars<-kernel_setup(n_of_chains,next_prior_draws)
    # log for debug:
    log_kernel[[j]]<-list(next_prior_draws=next_prior_draws,
                          bandwidth=kernel_vars$bandwidth,
                          loopcount=kernel_vars$loopcount,
                          inits=kernel_vars$inits)

  }
  stan_kernel_time[[2]]<-Sys.time()



  ######################################################

  # using hypercube counts of posterior draws

  ## deprecated bandwidth calculation
  # bandwidth<-median(c((max(first_samples$beta0)-min(first_samples$beta0))/parameter_bins,
  #                     (max(first_samples$beta1)-min(first_samples$beta1))/parameter_bins,
  #                     (max(first_samples$beta2)-min(first_samples$beta2))/parameter_bins))*bw_scaling



  hypercube_setup<-function(n_of_chains,
                            parameter_bins,
                            next_prior_draws,
                            hartigan_p_threshold=0.05,
                            multimodal_boost=1.5) {

    hypercube_posterior<-as.data.frame(next_prior_draws)

    # divide into parameter bins
    parameter_bin_centres<-cbind(min(next_prior_draws[,1])+
                                   ((max(next_prior_draws[,1])-min(next_prior_draws[,1]))*
                                      ((1:parameter_bins)-0.5)/parameter_bins),
                                 min(next_prior_draws[,2])+
                                   ((max(next_prior_draws[,2])-min(next_prior_draws[,2]))*
                                      ((1:parameter_bins)-0.5)/parameter_bins),
                                 min(next_prior_draws[,3])+
                                   ((max(next_prior_draws[,3])-min(next_prior_draws[,3]))*
                                      ((1:parameter_bins)-0.5)/parameter_bins))
    next_prior_draws<-cbind(cut(next_prior_draws[,1],breaks=parameter_bins,labels=FALSE),
                            cut(next_prior_draws[,2],breaks=parameter_bins,labels=FALSE),
                            cut(next_prior_draws[,3],breaks=parameter_bins,labels=FALSE))
    p<-ncol(next_prior_draws)
    next_prior_draws<-cbind(parameter_bin_centres[as.numeric(next_prior_draws[,1]),1],
                            parameter_bin_centres[as.numeric(next_prior_draws[,2]),2],
                            parameter_bin_centres[as.numeric(next_prior_draws[,3]),3])
    next_prior_draws<-as.data.frame(next_prior_draws)
    colnames(next_prior_draws)<-c("beta0_bins","beta1_bins","beta2_bins")

    # the binned version
    next_prior_bins<-tally(group_by(next_prior_draws,beta0_bins,beta1_bins,beta2_bins))
    cube_counts<-next_prior_bins$n
    next_prior_bins<-select(next_prior_bins,-n)

    # get Sheather-Jones bandwidth
    bandwidth<-apply(next_prior_draws,2,bw.SJ)
    # check for multimodality
    # loop over the parameters
    dipstats<-rep(NA,3)
    loopcount<-1
    dip_p<-rep(0.01,3)
    while(loopcount<100 & min(dip_p)<hartigan_p_threshold) {
      # get maximum Hartigans' dip statistic and increase bandwidth until non-sig
      for(i in 1:3) {
        tempdens<-density(next_prior_draws[,i],bw=bandwidth[i])
        tempscale<-n_of_chains*n_of_draws_per_chain/round(sum(tempdens$y))
        dip_p[i]<-unlist(diptest::dip.test(rep(tempdens$x,round(tempscale*tempdens$y)))$p.value)
        if(loopcount>1 & dip_p[i]<hartigan_p_threshold) { bandwidth[i]<-bandwidth[i]*multimodal_boost }
      }
      loopcount<-loopcount+1
    }
    if(loopcount>99) { stop("Unable to find unimodal univariate kernel bandwidth after 100 expansions") }

    return(list(next_prior_draws=next_prior_draws,
                next_prior_bins=next_prior_bins,
                cube_counts=cube_counts,
                parameter_bin_centres=parameter_bin_centres,
                bandwidth=bandwidth,
                loopcount=loopcount,
                hypercube_posterior=hypercube_posterior))
  }

  # setup after first batch of data
  next_prior_draws<-cbind(first_samples$beta0,
                          first_samples$beta1,
                          first_samples$beta2)
  next_prior_draws<-next_prior_draws[sample.int(n=NROW(next_prior_draws),
                                                size=n_of_chains*n_of_draws_per_chain),]
  hypercube_vars<-hypercube_setup(n_of_chains,
                                  parameter_bins,
                                  next_prior_draws)
  next_prior_draws<-hypercube_vars$next_prior_bins # replace with binned version

  # # visual check
  # for(par in 1:3) {
  #   plot(density(rep(unlist(next_prior_draws[,par]),hypercube_vars$cube_counts),
  #                bw=hypercube_vars$bandwidth[par]))
  # }

  # get initial values
  hypercube_inits<-init_draw(n_of_chains,next_prior_draws)

  # log for debug:
  log_hypercube[[1]]<-list(hypercube_vars=hypercube_vars,
                           inits=hypercube_inits)

  stan_summary_kernel_cube<-array(NA,dim=c(3,2,batches))
  stan_summary_kernel_cube[,,1]<-summary(stan_first_fit)$summary[1:3,c(1,3)]
  stan_kernel_cube_time<-list(Sys.time())
  for(j in 2:batches) {
    cat(paste("now running simulation number",currentiter,
              "-- hypercube model -- batch",j,"of",batches,"\n"))

    stan_kernel_cube_fit<-sampling(stan_kernel_cube_fit_model,
                                   data=list(n=n/batches,
                                             y=data_batch[[j]]$y,
                                             x1=data_batch[[j]]$x1,
                                             x2=data_batch[[j]]$x2,
                                             k=NROW(next_prior_draws),
                                             k_draws=n_of_chains*n_of_draws_per_chain,
                                             p=NCOL(next_prior_draws),
                                             prior=as.matrix(next_prior_draws),
                                             count=hypercube_vars$cube_counts,
                                             bandwidth=hypercube_vars$bandwidth),
                                   chains=n_of_chains,
                                   cores=4,
                                   iter=2500+n_of_draws_per_chain,
                                   warmup=2500,
                                   seed=stan_kernel_cube_fit_seed+4577*j,
                                   init=hypercube_inits)
    print(stan_kernel_cube_fit)
    stan_summary_kernel_cube[,,j]<-summary(stan_kernel_cube_fit)$summary[1:3,c(1,3)]
    next_prior_draws<-extract(stan_kernel_cube_fit)$beta
    next_prior_draws<-next_prior_draws[sample.int(n=NROW(next_prior_draws),
                                                  size=n_of_chains*n_of_draws_per_chain),]

    hypercube_vars<-hypercube_setup(n_of_chains,
                                    parameter_bins,
                                    next_prior_draws)
    next_prior_draws<-hypercube_vars$next_prior_bins # replace with binned version

    # get initial values
    hypercube_inits<-init_draw(n_of_chains,next_prior_draws)

    # log for debug:
    log_hypercube[[j]]<-list(hypercube_vars=hypercube_vars,
                             inits=hypercube_inits)

  }
  stan_kernel_cube_time[[2]]<-Sys.time()




  ######################################################
  # multivariate beta kernel densities for priors

  # get posterior from first batch (and possibly down-sample)
  next_prior_draws<-cbind(first_samples$beta0,
                          first_samples$beta1,
                          first_samples$beta2)
  next_prior_draws<-next_prior_draws[sample.int(n=NROW(next_prior_draws),
                                                size=n_of_chains*
                                                  n_of_draws_per_chain_beta),]

  beta_setup<-function(n_of_chains,
                       next_prior_draws,
                       hartigan_p_threshold=0.05,
                       multimodal_boost=1.5) {
    p<-ncol(next_prior_draws)
    # get Sheather-Jones bandwidths
    bandwidth<-apply(next_prior_draws,2,bw.SJ)

    # check for multimodality
    # loop over the parameters
    dipstats<-rep(NA,p)
    loopcount<-0
    dip_p<-rep(0.01,p)
    while(loopcount<100 & min(dip_p)<hartigan_p_threshold) {
      # get maximum Hartigans' dip statistic and increase bandwidth by 50% until non-sig
      for(i in 1:p) {
        tempdens<-density(next_prior_draws[,i],bw=bandwidth[i])
        tempscale<-n_of_chains*n_of_draws_per_chain/round(sum(tempdens$y))
        dip_p[i]<-unlist(diptest::dip.test(rep(tempdens$x,round(tempscale*tempdens$y)))$p.value)
      }
      if(loopcount>0) { bandwidth<-bandwidth*multimodal_boost }
      loopcount<-loopcount+1
    }
    if(loopcount>99) { stop("Unable to find unimodal univariate kernel bandwidth after 100 expansions") }

    # convert to beta width
    beta_widths<-bandwidth*6 # Â±3 SDs

    # get initial values
    inits<-init_draw(n_of_chains,next_prior_draws)



    return(list(next_prior_draws=next_prior_draws,
                bandwidth=bandwidth,
                loopcount=loopcount,
                beta_widths=beta_widths,
                inits=inits))
  }

  # setup after first batch of data
  beta_vars<-beta_setup(n_of_chains,next_prior_draws)

  # log for debug:
  log_beta[[1]]<-beta_vars

  stan_summary_beta<-array(NA,dim=c(3,2,batches))
  stan_summary_beta[,,1]<-summary(stan_first_fit)$summary[1:3,c(1,3)]
  stan_beta_time<-list(Sys.time())

  # loop over updates
  for(j in 2:batches) {
    cat(paste("now running simulation number",currentiter,
              "-- beta model -- batch",j,"of",batches,"\n"))

    stan_beta_fit<-sampling(stan_beta_fit_model,
                            data=list(n=n/batches,
                                      y=data_batch[[j]]$y,
                                      x1=data_batch[[j]]$x1,
                                      x2=data_batch[[j]]$x2,
                                      k=NROW(beta_vars$next_prior_draws),
                                      p=NCOL(beta_vars$next_prior_draws),
                                      beta_widths=beta_vars$beta_widths,
                                      prior=beta_vars$next_prior_draws,
                                      betapars=betapars),
                            chains=n_of_chains,
                            cores=4,
                            iter=2500+n_of_draws_per_chain,
                            warmup=2500,
                            seed=stan_beta_fit_seed+968547*j,
                            init=beta_vars$inits)

    stan_summary_beta[,,j]<-summary(stan_beta_fit)$summary[1:3,c(1,3)]
    next_prior_draws<-extract(stan_beta_fit)$beta
    next_prior_draws<-as.data.frame(next_prior_draws)

    beta_vars<-beta_setup(n_of_chains,next_prior_draws)

    # log for debug:
    log_beta[[j]]<-beta_vars

  }
  stan_beta_time[[2]]<-Sys.time()






  ######################################################
  # compile all results
  results<-list(mles=mles,
                stan_summary_all=stan_summary_all,
                stan_all_time=stan_all_time,
                stan_summary_stats=stan_summary_stats,
                stan_normal_stats_time=stan_normal_stats_time,
                stan_summary_kernel=stan_summary_kernel,
                stan_kernel_time=stan_kernel_time,
                stan_summary_kernel_cube=stan_summary_kernel_cube,
                stan_kernel_cube_time=stan_kernel_cube_time,
                stan_summary_beta=stan_summary_beta,
                stan_beta_time=stan_beta_time,
                r_seed=r_seed,
                stan_all_fit_seed=stan_all_fit_seed,
                stan_first_fit_seed=stan_first_fit_seed,
                stan_next_fit_seed=stan_next_fit_seed,
                stan_kernel_fit_seed=stan_kernel_fit_seed,
                stan_kernel_cube_fit_seed=stan_kernel_cube_fit_seed,
                data_batches=data_batch,
                log_normal=log_normal,
                log_kernel=log_kernel,
                log_hypercube=log_hypercube,
                log_beta=log_beta)
  return(results)
}



###########################################################
# Section 3                                               #
# Run the simulation                                      #
###########################################################


iter<-334
for(k in 1:iter) {
  monitorfile<-file("monitorfile.txt","w")
  cat(paste("Now running iteration",k), file=monitorfile)
  close(monitorfile)
  all_results<-try( kernelsim(n=2000,
                              batches=10,
                              n_of_chains=4,
                              true_beta0=2,
                              true_beta1=0.5,
                              true_beta2=(-1.5),
                              r_seed=r_overall_seed+10000+(3*k),
                              stan_all_fit_seed=stan_overall_seed+10000+(3*k),
                              stan_first_fit_seed=stan_overall_seed+20000+(3*k),
                              stan_next_fit_seed=stan_overall_seed+30000+(3*k),
                              stan_kernel_fit_seed=stan_overall_seed+40000+(3*k),
                              stan_kernel_cube_fit_seed=stan_overall_seed+50000+(3*k),
                              stan_beta_fit_seed=stan_overall_seed+60000+(3*k),
                              n_of_draws_per_chain=1000,
                              n_of_draws_per_chain_beta=1000,
                              parameter_bins=10,
                              bw_scaling=0.7,
                              stan_all_fit_model=stan_all_fit_model,
                              stan_next_fit_model=stan_next_fit_model,
                              stan_kernel_fit_model=stan_kernel_fit_model,
                              stan_kernel_cube_fit_model=stan_kernel_cube_fit_model,
                              stan_beta_fit_model=stan_beta_fit_model,
                              betapars=betapars,
                              currentiter=k))
  saveRDS(all_results,file=paste0("sim_results_",k,".rds"))
}
